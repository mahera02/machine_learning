{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Problem_5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "vXLYvrT4kp-T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import ndimage\n",
        "from skimage import util \n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RVQuJNbWH27g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Rounding the grey values of the images to 1 and 0 to obtain black and white images**"
      ]
    },
    {
      "metadata": {
        "id": "K9PGisvEH2Co",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First I tried below method for converting gray scale images to binary but as it is very slow, I am replacing it below by using cv2 library which is fast\n",
        "\n",
        "def binarize_array(numpy_array, threshold=127):\n",
        "    \"\"\"Binarize a numpy array.\"\"\"\n",
        "    for i in range(len(numpy_array)):\n",
        "        for j in range(len(numpy_array[0])):\n",
        "            if numpy_array[i][j] > threshold:\n",
        "                numpy_array[i][j] = 255\n",
        "            else:\n",
        "                numpy_array[i][j] = 0\n",
        "    return numpy_array\n",
        "\n",
        "# for i in range(len(train_images_original)):\n",
        "#     train_images_original[i] = binarize_array(train_images_original[i])\n",
        "\n",
        "# for i in range(len(test_images_original)):\n",
        "#     test_images_original[i] = binarize_array(test_images_original[i])\n",
        "  \n",
        "#plt.grid(None)\n",
        "#plt.imshow(binarize_array(train_images_original[0]))\n",
        "#binarize_array(train_images_original[0]).shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_vVzitqqL2Vv",
        "colab_type": "code",
        "outputId": "27c22e5f-6156-4e50-a614-2932e2cc2b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1350
        }
      },
      "cell_type": "code",
      "source": [
        "# Conversion Using cv2\n",
        "\n",
        "threshold = 127\n",
        "for i in range(len(train_images_original)):\n",
        "    train_images_original[i] = cv2.threshold(train_images_original[i], threshold, 255, cv2.THRESH_BINARY)[1]\n",
        "    \n",
        "\n",
        "for i in range(len(test_images_original)):\n",
        "    test_images_original[i] = cv2.threshold(test_images_original[i], threshold, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "  \n",
        "\n",
        "print(train_images_original[0])\n",
        "\n",
        "# checking the binary image for any index\n",
        "plt.grid(None)\n",
        "plt.imshow(train_images_original[0])\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255\n",
            "  255   0 255 255 255   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 255 255 255 255 255 255 255\n",
            "  255 255 255 255 255   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 255 255 255 255 255 255 255 255 255\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 255 255 255 255 255 255 255 255 255\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 255   0 255 255 255   0   0   0 255\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 255 255   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 255 255 255   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 255 255   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 255 255 255   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255 255   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255 255\n",
            "  255   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255\n",
            "  255 255   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255\n",
            "  255 255   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255 255\n",
            "  255 255   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 255 255 255 255 255\n",
            "  255 255   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 255 255 255 255 255 255\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 255 255 255 255 255 255   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 255 255 255 255 255 255 255   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 255 255 255 255 255 255 255 255   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 255 255 255 255 255 255 255   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f07faf96160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pCSB-32Wlxcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        },
        "outputId": "a321c03d-c1bf-4c7a-ecda-70ef41a3b518"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_images_original = train_images_original / 255;\n",
        "test_images_original  = test_images_original  / 255; \n",
        "\n",
        "print(train_images_original[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xf_oEJaNqG57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6dc91831-584c-48e0-f79e-7b23bb6e2c7a"
      },
      "cell_type": "code",
      "source": [
        "# creating vectors to hold connected component data - shape ( number of samples, 1)\n",
        "\n",
        "connected_components_train = np.zeros_like(train_labels_original)\n",
        "connected_components_test  = np.zeros_like(test_labels_original)\n",
        "print(train_labels_original,)\n",
        "print(connected_components_train,)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 ... 5 6 8]\n",
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gpQf4DQh6Q_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        },
        "outputId": "30cfe67f-c7c2-4e16-dcbc-b6706d8a3762"
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(train_images_original)):\n",
        "  train_images_original[i]=util.invert(train_images_original[i])\n",
        "print(train_images_original[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5PlGjN5oqftx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1495
        },
        "outputId": "ddd4bb2f-e104-4262-b468-684504bc8743"
      },
      "cell_type": "code",
      "source": [
        "# using scipy ndimage to get connected components easily\n",
        "\n",
        "for i in range(len(connected_components_train)):\n",
        "  labeled, nr_objects = ndimage.label(util.invert(train_images_original[i]))\n",
        "  #print(util.invert(train_images_original[i]))  \n",
        "  #print(labeled)\n",
        "  connected_components_train[i] = nr_objects\n",
        "\n",
        "print(util.invert(train_images_original[0]))  \n",
        "print(labeled)\n",
        "\n",
        "for i in range(len(connected_components_test)):\n",
        "  labeled, nr_objects = ndimage.label(util.invert(test_images_original[i]))\n",
        "  connected_components_test[i] = nr_objects"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  1. 1. 1. 1.]]\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 2 2 2 2 2 0 1 1 0 0 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 0 0 2 2 2 2 2 2 2 0 0 0 0 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 0 2 2 2 2 2 2 2 2 0 0 0 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 0 0 2 2 2 2 2 2 0 0 0 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 0 2 2 2 2 2 0 0 0 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 0 0 2 2 2 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 0 0 2 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 0 0 0 3 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 0 0 3 3 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 0 0 0 3 3 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 0 0 3 3 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t6auL5tY1yKj",
        "colab_type": "code",
        "outputId": "7b7259eb-af42-4532-b4d4-ffc2915c403a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n",
        "\n",
        "train_images = train_images_original.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels_original,10)\n",
        "test_labels = to_categorical(test_labels_original,10)\n",
        "\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)\n",
        "\n",
        "\n",
        "connected_components_train = connected_components_train / 4\n",
        "connected_components_test = connected_components_test / 4\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GUqq8E3e4Fc5",
        "colab_type": "code",
        "outputId": "ec04e7c7-b582-43d3-ae34-862227a316c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1199
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "\n",
        "\n",
        "#network = models.Sequential()\n",
        "\n",
        "#network.add(Dense(units = 64, activation = 'sigmoid'))\n",
        "\n",
        "#network.add(Dense(units = 10, activation = 'softmax'))\n",
        "\n",
        "# training data\n",
        "input_shape = keras.layers.Input((28*28,))\n",
        "\n",
        "# hand crafed connected component feature\n",
        "connected_component_feature = keras.layers.Input((1,))\n",
        "\n",
        "# fully connected layer with 64 neurons and sigmoid activation\n",
        "image_vector = Dense(64, activation='sigmoid')(input_shape)\n",
        "\n",
        "# concatenating handcrafted features and output of first dense layer\n",
        "network  = keras.layers.add([image_vector, connected_component_feature])   \n",
        "\n",
        "# final fully connected layer with 10 neurons and softmax activation\n",
        "network  = Dense(10, activation='softmax')(network)\n",
        "\n",
        "# final model\n",
        "network  = keras.Model([input_shape, connected_component_feature], network)\n",
        "\n",
        "\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "network.compile(optimizer=sgd,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "epochs = 30\n",
        "History = network.fit([train_images, \n",
        "                      connected_components_train],\n",
        "                      train_labels,\n",
        "                      epochs=epochs, \n",
        "                      batch_size=128)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 1.0092 - acc: 0.7733\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.4382 - acc: 0.8941\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.3467 - acc: 0.9101\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.3058 - acc: 0.9177\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.2806 - acc: 0.9235\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2622 - acc: 0.9273\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2482 - acc: 0.9311\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.2365 - acc: 0.9338\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2262 - acc: 0.9364\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2177 - acc: 0.9389\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.2097 - acc: 0.9406\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2027 - acc: 0.9428\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.1962 - acc: 0.9441\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.1902 - acc: 0.9461\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.1847 - acc: 0.9474\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.1798 - acc: 0.9487\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.1748 - acc: 0.9498\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.1704 - acc: 0.9522\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.1662 - acc: 0.9527\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1623 - acc: 0.9540\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1585 - acc: 0.9547\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1548 - acc: 0.9564\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.1515 - acc: 0.9567\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1482 - acc: 0.9581\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.1453 - acc: 0.9583\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.1425 - acc: 0.9594\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.1397 - acc: 0.9598\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.1371 - acc: 0.9605\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.1345 - acc: 0.9615\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.1320 - acc: 0.9623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "il2dGtts59zq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#evaluate function: Returns the loss value & metrics values for the model in test mode\n",
        "metrics = network.evaluate([test_images,connected_components_test], test_labels, verbose=0)\n",
        "print('Test loss:', metrics[0])\n",
        "print('Test accuracy:', metrics[1])\n",
        "\n",
        "accuracyplot = plt.plot(range(1,31),History.history['acc'],range(1,31),History.history['val_acc'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Training Accuracy','Test Accuracy'))\n",
        "plt.show(accuracyplot)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}