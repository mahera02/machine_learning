{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Problem_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "nmhTVRGsVBh_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading the MNIST data set through Keras**"
      ]
    },
    {
      "metadata": {
        "id": "3UFi5pw44gHF",
        "colab_type": "code",
        "outputId": "85a7774a-b1ec-49b9-dc5a-218438e832ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kt9zW_28WeIw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "printing original values"
      ]
    },
    {
      "metadata": {
        "id": "jXW4rjttWjmh",
        "colab_type": "code",
        "outputId": "00932735-1d3f-44a3-b1b9-303f405ad04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "train_images_original.shape, train_labels_original, test_images_original.shape, test_labels_original.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28),\n",
              " array([5, 0, 4, ..., 5, 6, 8], dtype=uint8),\n",
              " (10000, 28, 28),\n",
              " (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "gxGF4kP5WTSq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preparing the image data**"
      ]
    },
    {
      "metadata": {
        "id": "Vy8UC4a4WS22",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images_original.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "train_images = train_images.T\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "test_images = test_images.T\n",
        "\n",
        "train_labels_original = train_labels_original.T\n",
        "test_labels_original = test_labels_original.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K5imu-EeMP7s",
        "colab_type": "code",
        "outputId": "be0ca451-e629-4c98-9827-ee7c61458e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "print(train_labels_original.shape)\n",
        "print(test_labels_original.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 60000)\n",
            "(784, 10000)\n",
            "(60000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xjVXxQ7l43rO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preparing the train labels ( converting intergers to binary)**"
      ]
    },
    {
      "metadata": {
        "id": "ftLmk4m649nN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb62c613-d5bf-451b-cbaa-b52a80baaef9"
      },
      "cell_type": "code",
      "source": [
        "predict_train_labels_original = to_categorical(train_labels_original,10)\n",
        "predict_test_labels_original = to_categorical(test_labels_original,10)\n",
        "predict_train_labels_original.shape\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "Qc2MNy5SWrW-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "printing new values"
      ]
    },
    {
      "metadata": {
        "id": "UM7GoBRgWtR9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1UdB638kqqgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Initialize the parameters epochs,batch size and learning rate for training the data set**"
      ]
    },
    {
      "metadata": {
        "id": "ztCK9vw3OisT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn_rate = 0.1\n",
        "batch_size = 50\n",
        "epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Voy20j8Th4iU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Method Definitions for logistic regression, sigmoid and mini-batch stochastic gradient using binary cross entropy loss**"
      ]
    },
    {
      "metadata": {
        "id": "nIo1B1ZZh6Yc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_zeros(size):\n",
        "   weight = np.zeros(shape=(size, 1))\n",
        "   bias = 0\n",
        "   return weight,bias\n",
        "  \n",
        "  \n",
        "#Logistic Regression using binary cross entropy loss\n",
        "\n",
        "def binary_entropy_loss_function(weight,bias,x,y):\n",
        "  z = np.dot(np.transpose(weight),x) + (bias)\n",
        "  activation = sigmoid(z)\n",
        "  loss_value = (-1/batch_size) * np.sum(y * np.log(activation) + (1 - y) * (np.log(1 - activation)))\n",
        "  \n",
        "  #computing gradient wrt weight and wrt to bias\n",
        "  dweight = (1 / batch_size) * np.dot(x, (activation - y).T)\n",
        "  dbias = (1 / batch_size) * np.sum(activation - y)\n",
        "  gradient = {\"dweight\":dweight,\"dbias\":dbias }\n",
        "  loss_value = np.squeeze(loss_value)\n",
        "  \n",
        "  return gradient,loss_value\n",
        "\n",
        "\n",
        "#input to the sigmoid function (our algorithmâ€™s prediction using Logistic regression  e.g. z= wx + b)\n",
        "\n",
        "def sigmoid(z): \n",
        "  return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_derivative(z):\n",
        "  return sigmoid(z)*(1-sigmoid(z))\n",
        "\n",
        "  \n",
        "# Implementing mini-batch stochastic gradient descent for back propogation\n",
        "\n",
        "def minibatchsgd(weight,bias,train_images,train_labels,epochs,learn_rate):\n",
        "  loss_values = []\n",
        "  for i in range(epochs):\n",
        "    for batch in get_mini_batches(np.transpose(train_images), np.transpose(train_labels), batch_size):\n",
        "      train_images_batch,train_labels_batch = batch\n",
        "      gradient,loss_value = binary_entropy_loss_function(weight,bias,np.transpose(train_images_batch),np.transpose(train_labels_batch))\n",
        "      gradient_weight =gradient[\"dweight\"]\n",
        "      gradient_bias = gradient[\"dbias\"]\n",
        "      weight = weight - learn_rate*gradient_weight\n",
        "      bias = bias - learn_rate*gradient_bias\n",
        "    loss_values.append(loss_value)\n",
        "    \n",
        "  initials = {\"weight\":weight,\"bias\":bias}\n",
        "  gradients = {\"dweight\":gradient_weight ,\"dbias\":gradient_bias}\n",
        "        \n",
        "  return initials,gradients,loss_values\n",
        "\n",
        "\n",
        "def get_mini_batches(train_images,train_labels,batch_size):\n",
        "  for i in range(0, train_images.shape[0]- batch_size+1, batch_size):\n",
        "    last_slice = slice(i, i + batch_size)\n",
        "    yield train_images[last_slice],train_labels[last_slice]\n",
        "    \n",
        "\n",
        "# normalizing and predicting the values\n",
        "\n",
        "def prediction(weight, bias, train_images):\n",
        "  \n",
        "   m = train_images.shape[1] \n",
        "   #print('m',m) \n",
        "   labels_prediction = np.zeros((1, m)) \n",
        "   weight = weight.reshape(train_images.shape[0], 1) \n",
        "   #print(weight.T.shape)\n",
        "   activation = sigmoid(np.dot(weight.T, train_images) + bias)\n",
        "  \n",
        "   #normalizing the predicted values\n",
        "   for i in range(activation.shape[1]):\n",
        "      labels_prediction[0, i] = 1 if activation[0, i] > 0.5 else 0 \n",
        "  \n",
        "   return labels_prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GQP4qvbo8ANL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training the network to find the classifier with maximum accuracy**"
      ]
    },
    {
      "metadata": {
        "id": "IaSda0dWnK-W",
        "colab_type": "code",
        "outputId": "f904b50b-1d66-4775-e93a-52fd27c96573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "cell_type": "code",
      "source": [
        "# network model for 10 classifiers\n",
        "  \n",
        "  for digit_classifier in range(0,10):\n",
        "    #binary classification for one classifier_digit from 0 to 9\n",
        "    modified_train_label = np.array(train_labels_original);\n",
        "    modified_train_label = np.where(modified_train_label == digit_classifier, 1, 0)\n",
        "      \n",
        "    modified_test_label = np.array(test_labels_original);\n",
        "    modified_test_label = np.where(modified_test_label == digit_classifier, 1, 0)\n",
        "    \n",
        "    #training the network model to obtain different weight and bias\n",
        "    train_images.shape[0]\n",
        "    weight, bias = initialize_zeros(train_images.shape[0])\n",
        "    initials,gradients,loss_values = minibatchsgd(weight, bias, train_images, modified_train_label, epochs, learn_rate)\n",
        "    weight= initials[\"weight\"]\n",
        "    bias=initials[\"bias\"]\n",
        "    \n",
        "    #based on trained weights and bias values we predict the labels\n",
        "    train_labels_prediction = prediction(weight, bias, train_images)\n",
        "    test_labels_prediction = prediction(weight,bias, test_images)\n",
        "    #print(train_labels_prediction.shape)\n",
        "    #print(predict_train_labels_original.shape)\n",
        "    \n",
        "    predict_train_labels_original[:,[digit_classifier]] = train_labels_prediction.T\n",
        "    predict_test_labels_original[:,[digit_classifier]] = test_labels_prediction.T\n",
        "    \n",
        "    #corresponding 0 to 9 train and test classifier accuracy\n",
        "    print(\"Digit \" + str(digit_classifier) +\" train accuracy : {} %\".format(100 - np.mean(np.abs(train_labels_prediction - modified_train_label)) * 100))\n",
        "    print(\"Digit \" + str(digit_classifier) +\" test accuracy : {} %\".format(100 - np.mean(np.abs(test_labels_prediction - modified_test_label)) * 100))\n",
        "\n",
        "     \n",
        "  train_labels_original = keras.utils.to_categorical(train_labels_original, 10)\n",
        "  test_labels_original = keras.utils.to_categorical(test_labels_original, 10)\n",
        "  print(train_labels_original.shape)\n",
        "  print(predict_train_labels_original.shape)\n",
        "    \n",
        "  #overall test and train classifier accuracy of the network\n",
        "  print(\"Overall train accuracy: {} %\".format(100 - np.mean(np.abs(predict_train_labels_original - train_labels_original)) * 100))\n",
        "  print(\"Overall test accuracy: {} %\".format(100 - np.mean(np.abs(predict_test_labels_original - test_labels_original)) * 100))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Digit 0 train accuracy : 99.26666666666667 %\n",
            "Digit 0 test accuracy : 99.18 %\n",
            "Digit 1 train accuracy : 99.17 %\n",
            "Digit 1 test accuracy : 99.32 %\n",
            "Digit 2 train accuracy : 97.835 %\n",
            "Digit 2 test accuracy : 97.72 %\n",
            "Digit 3 train accuracy : 97.62833333333333 %\n",
            "Digit 3 test accuracy : 97.85 %\n",
            "Digit 4 train accuracy : 98.42166666666667 %\n",
            "Digit 4 test accuracy : 98.33 %\n",
            "Digit 5 train accuracy : 97.44 %\n",
            "Digit 5 test accuracy : 97.65 %\n",
            "Digit 6 train accuracy : 98.80666666666667 %\n",
            "Digit 6 test accuracy : 98.77 %\n",
            "Digit 7 train accuracy : 98.49666666666667 %\n",
            "Digit 7 test accuracy : 98.51 %\n",
            "Digit 8 train accuracy : 95.96333333333334 %\n",
            "Digit 8 test accuracy : 96.07 %\n",
            "Digit 9 train accuracy : 96.43166666666667 %\n",
            "Digit 9 test accuracy : 96.5 %\n",
            "(60000, 10)\n",
            "(60000, 10)\n",
            "Overall train accuracy: 97.94599991291761 %\n",
            "Overall test accuracy: 97.99000006169081 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}